{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n%matplotlib inline\nnp.random.seed(0)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-12T08:45:28.934035Z","iopub.execute_input":"2022-09-12T08:45:28.935144Z","iopub.status.idle":"2022-09-12T08:45:28.943703Z","shell.execute_reply.started":"2022-09-12T08:45:28.935095Z","shell.execute_reply":"2022-09-12T08:45:28.942788Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"##Import e describe dos DataFrames\ntest = pd.read_csv('../input/titanic/test.csv')\ntrain = pd.read_csv('../input/titanic/train.csv')\ntest.describe()\ntrain.describe()","metadata":{"execution":{"iopub.status.busy":"2022-09-12T08:45:28.968335Z","iopub.execute_input":"2022-09-12T08:45:28.969054Z","iopub.status.idle":"2022-09-12T08:45:29.030604Z","shell.execute_reply.started":"2022-09-12T08:45:28.969004Z","shell.execute_reply":"2022-09-12T08:45:29.029454Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"##Info e localização das partes sem dados\ntest.info()\ntrain.info()\nprint(test.isnull().sum())\nprint(train.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2022-09-12T08:45:29.032971Z","iopub.execute_input":"2022-09-12T08:45:29.033708Z","iopub.status.idle":"2022-09-12T08:45:29.061471Z","shell.execute_reply.started":"2022-09-12T08:45:29.033660Z","shell.execute_reply":"2022-09-12T08:45:29.060290Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"##Separação das features desejadas e retiradas de dados nulos\ntest1 = test.loc[:,['PassengerId', 'Age', 'SibSp', 'Parch', 'Fare']]\ntrain1 = train.loc[:,['PassengerId', 'Survived', 'Age', 'SibSp', 'Parch', 'Fare']]\ntrain1=train1.dropna()\ntest1 = test1.fillna(0)\ndisplay(train1)\ndisplay(test1)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T08:45:29.062972Z","iopub.execute_input":"2022-09-12T08:45:29.063931Z","iopub.status.idle":"2022-09-12T08:45:29.101137Z","shell.execute_reply.started":"2022-09-12T08:45:29.063885Z","shell.execute_reply":"2022-09-12T08:45:29.099947Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"##Criação da feature de intervalo de idade e plot dos graficos relacionando as features e o target\nAge = ['(0-10)','(10-20)','(20-30)','(30-40)','(40-50)','(50-60)','(60- 70)','(+70)']\npc = [0,10,20,30,40,50,60,70,np.inf]\ntrain1['AgeInterval'] = pd.cut(train1['Age'],pc,labels=Age)\ndisplay(train1)\nbp1 = sns.barplot(data=train1, x='AgeInterval', y='Survived')\nbp2 = sns.barplot(data=train1, x='SibSp', y='Survived')\nbp3 = sns.barplot(data=train1, x='Parch', y='Survived')\ndisplay(bp1)\ndisplay(bp2)\ndisplay(bp3)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-12T08:45:29.104206Z","iopub.execute_input":"2022-09-12T08:45:29.105170Z","iopub.status.idle":"2022-09-12T08:45:29.875586Z","shell.execute_reply.started":"2022-09-12T08:45:29.105126Z","shell.execute_reply":"2022-09-12T08:45:29.874525Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"##Retirada das features não utilizadas e realização do test de precisão da predict\nX = train1.drop(['Survived','AgeInterval','PassengerId'],axis = 1)\ndisplay(X)\ntgt = train1[\"Survived\"]\ntrain_X, val_X, train_y, val_y = train_test_split(X, tgt,test_size=0.20, random_state = 0)\nmodel_test = RandomForestClassifier()\nmodel_test.fit(train_X,train_y)\npredict = model_test.predict(val_X)\naccuracy_score(predict,val_y)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T08:45:29.876956Z","iopub.execute_input":"2022-09-12T08:45:29.877445Z","iopub.status.idle":"2022-09-12T08:45:30.101983Z","shell.execute_reply.started":"2022-09-12T08:45:29.877398Z","shell.execute_reply":"2022-09-12T08:45:30.100925Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"##Retirada da feature indesejada e realização da predict transformada em DataFrame\ntest2 = test1.drop('PassengerId', axis=1)\ndisplay(test2)\nct = test['PassengerId']\nprediction= model_test.predict(test2)\nres = pd.DataFrame({'PassengerId' : ct, 'Survived' : prediction})\nres.to_csv('submission.csv', index=False)\nres.shape\ndisplay(res)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T08:45:30.103250Z","iopub.execute_input":"2022-09-12T08:45:30.103630Z","iopub.status.idle":"2022-09-12T08:45:30.152414Z","shell.execute_reply.started":"2022-09-12T08:45:30.103598Z","shell.execute_reply":"2022-09-12T08:45:30.151541Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"##7\n##Mostra os dados de cada coluna e o total de dados com valor nulo\ntest.info()\ntrain.info()\nprint(test.isnull().sum())\nprint(train.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2022-09-12T08:45:30.154064Z","iopub.execute_input":"2022-09-12T08:45:30.155009Z","iopub.status.idle":"2022-09-12T08:45:30.180893Z","shell.execute_reply.started":"2022-09-12T08:45:30.154949Z","shell.execute_reply":"2022-09-12T08:45:30.179751Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"##Remove colunas não úteis para o que se é proposto\ntest.drop(['Cabin', 'Ticket'], axis=1)\ntrain.drop(['Cabin', 'Ticket'], axis=1)\n##Assume as idades faltando como a mediana de todas as idades\nma = test['Age'].median()\ntest['Age'] = test['Age'].fillna(ma)\ntma = np.median(train['Age'])\ntrain['Age'] = train['Age'].replace(np.nan, tma)\n#Assume todos os Fare faltando como a mediana de todos os Fares\nfm = test['Fare'].median()\ntest['Fare'] = test['Fare'].fillna(fm)\nfm = np.median(train['Fare'])\ntrain['Fare'] = train['Fare'].replace(np.nan, fm)\n##Assume os embarked faltando como a moda de todos os outros\nme = test['Embarked'].mode()\ntest['Embarked'] = test['Embarked'].fillna(me)\nem = train['Embarked'].mode()\ntrain['Embarked'] = train['Embarked'].fillna(em)\n##Divide e cria novas colunas de intervalos de 5 e 6 respectivamente para Age e Fare\ntrain['AgeInterval'] = pd.cut(train['Age'],5)\ntest['FareInterval'] = pd.qcut(test['Fare'],6)\ntest['AgeInterval'] = pd.cut(train['Age'],5)\ntrain['FareInterval'] = pd.qcut(test['Fare'],6)\n##Cria novo dataframe com as mudanças realizadas\ntest0= test.loc[:,['Age', 'Fare', 'Sex', 'Embarked', 'Pclass', 'AgeInterval', 'SibSp', 'Parch', 'FareInterval']]\ntrain0 = train.loc[:,['Age', 'Fare', 'Sex', 'Embarked', 'Pclass', 'Survived', 'AgeInterval', 'SibSp', 'Parch', 'FareInterval']]\ntrain0=train0.dropna()\ntest0=test0.dropna()\ndisplay(train0)\ndisplay(test0)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T08:45:30.182278Z","iopub.execute_input":"2022-09-12T08:45:30.182706Z","iopub.status.idle":"2022-09-12T08:45:30.251283Z","shell.execute_reply.started":"2022-09-12T08:45:30.182677Z","shell.execute_reply":"2022-09-12T08:45:30.250201Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"##8\n##Criação do dataframe de treino e de validation\nfrom sklearn.preprocessing import OneHotEncoder\ns = (train0.dtypes == 'object')\noc = list(s[s].index)\nprint(oc)\n##Função genérica de encode\ndef dummyEncode(pm):\n        columnsToEncode = list(pm.select_dtypes(include=['object']))\n        train1 = pm\n        test1 = test0\n        s = (train1.dtypes == 'object')\n        oc = list(s[s].index)\n        le = OneHotEncoder(handle_unknown='ignore', sparse=False)\n        for feature in oc:\n            try:\n                one = pd.DataFrame(le.fit_transform(train1[oc]))\n                one.index=pm.index\n            except:\n                print('Error encoding '+feature)\n            one.columns = le.get_feature_names(oc)\n            v = pd.DataFrame(le.transform(test1[oc]))\n            c = pd.concat([pm,one], axis=1)\n            return c\ntrainf=dummyEncode(train0)\ntestf=dummyEncode(test0)\ndisplay(testf)\nX = trainf.drop(['Survived','AgeInterval', 'FareInterval', 'Embarked', 'Sex', ],axis = 1)\n        ","metadata":{"execution":{"iopub.status.busy":"2022-09-12T08:45:30.252802Z","iopub.execute_input":"2022-09-12T08:45:30.253423Z","iopub.status.idle":"2022-09-12T08:45:30.303528Z","shell.execute_reply.started":"2022-09-12T08:45:30.253393Z","shell.execute_reply":"2022-09-12T08:45:30.302733Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\ntarget = trainf[\"Survived\"]\ntrain_X, val_X, train_y, val_y = train_test_split(X, target,test_size=0.20, random_state = 0)\nrf = RandomForestClassifier()\nrf.fit(train_X,train_y)\npdct = rf.predict(val_X)\naccuracy_score(pdct,val_y)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T08:46:07.577839Z","iopub.execute_input":"2022-09-12T08:46:07.578227Z","iopub.status.idle":"2022-09-12T08:46:07.752511Z","shell.execute_reply.started":"2022-09-12T08:46:07.578197Z","shell.execute_reply":"2022-09-12T08:46:07.751340Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn import datasets, linear_model\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.svm import LinearSVC\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n#Faz encode no dataframe e passa pelo Pipeline varias vezes\ndef pp(data, encoder, model, numerical_imputer, categorical_imputer):   \n        cat = [coln for coln in data.columns if data[coln].nunique() < 10 and data[coln].dtype == 'object']\n        num = [coln for coln in data.columns if data[coln].dtype in ['float64', 'int64'] and coln not in ['Survived', 'Name', 'PassengerId', 'Ticket', 'Cabin']]\n        feat = cat + num\n        target = data['Survived']\n        X = data[feat]\n        X_train, X_valid, y_train, y_valid = train_test_split(X, target, test_size=0.2, random_state=0)\n        # Preprocessing for numerical data\n        numerical_transformer = SimpleImputer(strategy=numerical_imputer)\n\n        # Preprocessing for categorical data\n        categorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),('encode', encoder)])\n\n        # Bundle preprocessing for numerical and categorical data\n        preprocessor = ColumnTransformer(transformers=[('num', numerical_transformer, num),('cat', categorical_transformer, cat)])\n        # Bundle preprocessing and modeling code in a pipeline\n        my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),('model', model)])\n\n        # Preprocessing of training data, fit model \n        my_pipeline.fit(X_train, y_train)\n\n        # Preprocessing of validation data, get predictions\n        preds = my_pipeline.predict(X_valid)\n\n        # Evaluate the model\n        score = accuracy_score(y_valid, preds)\n        scorep = (score * 100)\n        rt = print('enco:',encoder, numerical_transformer, scorep)\n        print(score.mean())\n        return rt\nrw = ['mean', 'median', 'most_frequent', 'constant']\nencoders = [OneHotEncoder(handle_unknown='ignore',sparse=False), OrdinalEncoder()]\ncateim='most_frequent'\nfor i in encoders:\n    for j in rw:\n        score = pp(train,i,RandomForestClassifier(),j,cateim)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T08:51:47.216739Z","iopub.execute_input":"2022-09-12T08:51:47.217149Z","iopub.status.idle":"2022-09-12T08:51:48.953705Z","shell.execute_reply.started":"2022-09-12T08:51:47.217116Z","shell.execute_reply":"2022-09-12T08:51:48.952680Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"##Faz o Cross Validation\nfrom sklearn.ensemble import GradientBoostingClassifier\ngbc= GradientBoostingClassifier(random_state = 0, n_iter_no_change = 100).fit(train_X, train_y)\ngbc.fit(train_X, train_y)\nah=gbc.predict(val_X)\naccuracy_score(ah,val_y)","metadata":{"execution":{"iopub.status.busy":"2022-09-12T08:58:35.383133Z","iopub.execute_input":"2022-09-12T08:58:35.384231Z","iopub.status.idle":"2022-09-12T08:58:35.541957Z","shell.execute_reply.started":"2022-09-12T08:58:35.384189Z","shell.execute_reply":"2022-09-12T08:58:35.540879Z"},"trusted":true},"execution_count":131,"outputs":[]}]}
